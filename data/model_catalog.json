{
  "models": [
    {
      "model_id": "meta-llama/Llama-3.1-8B-Instruct",
      "name": "Llama 3.1 8B Instruct",
      "provider": "Meta",
      "family": "llama3",
      "size_parameters": "8B",
      "context_length": 128000,
      "supported_tasks": ["chat", "instruction_following", "question_answering", "summarization"],
      "domain_specialization": ["general"],
      "license": "Llama 3.1 Community License",
      "license_type": "permissive",
      "min_gpu_memory_gb": 16,
      "recommended_for": ["chatbot", "customer_service", "qa_retrieval"],
      "approval_status": "approved",
      "notes": "Excellent general-purpose model with strong instruction following"
    },
    {
      "model_id": "meta-llama/Llama-3.1-70B-Instruct",
      "name": "Llama 3.1 70B Instruct",
      "provider": "Meta",
      "family": "llama3",
      "size_parameters": "70B",
      "context_length": 128000,
      "supported_tasks": ["chat", "instruction_following", "question_answering", "summarization", "reasoning"],
      "domain_specialization": ["general"],
      "license": "Llama 3.1 Community License",
      "license_type": "permissive",
      "min_gpu_memory_gb": 80,
      "recommended_for": ["code_generation", "content_creation", "summarization"],
      "approval_status": "approved",
      "notes": "High-performance model for complex reasoning tasks"
    },
    {
      "model_id": "mistralai/Mistral-7B-Instruct-v0.3",
      "name": "Mistral 7B Instruct v0.3",
      "provider": "Mistral AI",
      "family": "mistral",
      "size_parameters": "7B",
      "context_length": 32768,
      "supported_tasks": ["chat", "instruction_following", "code_generation"],
      "domain_specialization": ["general", "code"],
      "license": "Apache 2.0",
      "license_type": "permissive",
      "min_gpu_memory_gb": 14,
      "recommended_for": ["chatbot", "code_generation"],
      "approval_status": "approved",
      "notes": "Efficient and fast model with strong code capabilities"
    },
    {
      "model_id": "mistralai/Mixtral-8x7B-Instruct-v0.1",
      "name": "Mixtral 8x7B Instruct",
      "provider": "Mistral AI",
      "family": "mixtral",
      "size_parameters": "8x7B",
      "context_length": 32768,
      "supported_tasks": ["chat", "instruction_following", "code_generation", "multilingual"],
      "domain_specialization": ["general", "code", "multilingual"],
      "license": "Apache 2.0",
      "license_type": "permissive",
      "min_gpu_memory_gb": 80,
      "recommended_for": ["code_generation", "content_creation"],
      "approval_status": "approved",
      "notes": "Mixture-of-experts model with excellent multilingual support"
    },
    {
      "model_id": "mistralai/Mixtral-8x22B-Instruct-v0.1",
      "name": "Mixtral 8x22B Instruct",
      "provider": "Mistral AI",
      "family": "mixtral",
      "size_parameters": "8x22B",
      "context_length": 65536,
      "supported_tasks": ["chat", "instruction_following", "code_generation", "reasoning", "multilingual"],
      "domain_specialization": ["general", "code", "multilingual"],
      "license": "Apache 2.0",
      "license_type": "permissive",
      "min_gpu_memory_gb": 160,
      "recommended_for": ["content_creation", "code_generation"],
      "approval_status": "approved",
      "notes": "Largest Mixtral model with advanced reasoning capabilities"
    },
    {
      "model_id": "ibm-granite/granite-3.0-8b-instruct",
      "name": "Granite 3.0 8B Instruct",
      "provider": "IBM",
      "family": "granite",
      "size_parameters": "8B",
      "context_length": 128000,
      "supported_tasks": ["chat", "instruction_following", "summarization", "rag"],
      "domain_specialization": ["general", "enterprise"],
      "license": "Apache 2.0",
      "license_type": "permissive",
      "min_gpu_memory_gb": 16,
      "recommended_for": ["chatbot", "qa_retrieval", "summarization"],
      "approval_status": "approved",
      "notes": "Enterprise-focused model with strong RAG capabilities"
    },
    {
      "model_id": "google/gemma-2-9b-it",
      "name": "Gemma 2 9B IT",
      "provider": "Google",
      "family": "gemma",
      "size_parameters": "9B",
      "context_length": 8192,
      "supported_tasks": ["chat", "instruction_following", "question_answering"],
      "domain_specialization": ["general"],
      "license": "Gemma License",
      "license_type": "permissive",
      "min_gpu_memory_gb": 18,
      "recommended_for": ["chatbot", "customer_service"],
      "approval_status": "approved",
      "notes": "Compact and efficient model from Google"
    },
    {
      "model_id": "google/gemma-2-27b-it",
      "name": "Gemma 2 27B IT",
      "provider": "Google",
      "family": "gemma",
      "size_parameters": "27B",
      "context_length": 8192,
      "supported_tasks": ["chat", "instruction_following", "question_answering", "reasoning"],
      "domain_specialization": ["general"],
      "license": "Gemma License",
      "license_type": "permissive",
      "min_gpu_memory_gb": 54,
      "recommended_for": ["content_creation", "qa_retrieval"],
      "approval_status": "approved",
      "notes": "Larger Gemma model with improved reasoning"
    },
    {
      "model_id": "Qwen/Qwen2.5-7B-Instruct",
      "name": "Qwen 2.5 7B Instruct",
      "provider": "Alibaba Cloud",
      "family": "qwen",
      "size_parameters": "7B",
      "context_length": 131072,
      "supported_tasks": ["chat", "instruction_following", "code_generation", "multilingual"],
      "domain_specialization": ["general", "code", "multilingual"],
      "license": "Apache 2.0",
      "license_type": "permissive",
      "min_gpu_memory_gb": 14,
      "recommended_for": ["chatbot", "code_generation"],
      "approval_status": "approved",
      "notes": "Strong multilingual and code capabilities with large context window"
    },
    {
      "model_id": "Qwen/Qwen2.5-72B-Instruct",
      "name": "Qwen 2.5 72B Instruct",
      "provider": "Alibaba Cloud",
      "family": "qwen",
      "size_parameters": "72B",
      "context_length": 131072,
      "supported_tasks": ["chat", "instruction_following", "code_generation", "reasoning", "multilingual"],
      "domain_specialization": ["general", "code", "multilingual"],
      "license": "Apache 2.0",
      "license_type": "permissive",
      "min_gpu_memory_gb": 144,
      "recommended_for": ["code_generation", "content_creation"],
      "approval_status": "approved",
      "notes": "High-performance model with exceptional multilingual support"
    }
  ],
  "gpu_types": [
    {
      "gpu_type": "NVIDIA-L4",
      "memory_gb": 24,
      "compute_capability": "8.9",
      "typical_use_cases": ["inference"],
      "cost_per_hour_usd": 0.50,
      "availability": "high"
    },
    {
      "gpu_type": "NVIDIA-A10G",
      "memory_gb": 24,
      "compute_capability": "8.6",
      "typical_use_cases": ["inference", "training"],
      "cost_per_hour_usd": 1.00,
      "availability": "high"
    },
    {
      "gpu_type": "NVIDIA-A100-40GB",
      "memory_gb": 40,
      "compute_capability": "8.0",
      "typical_use_cases": ["inference", "training"],
      "cost_per_hour_usd": 3.00,
      "availability": "medium"
    },
    {
      "gpu_type": "NVIDIA-A100-80GB",
      "memory_gb": 80,
      "compute_capability": "8.0",
      "typical_use_cases": ["inference", "training"],
      "cost_per_hour_usd": 4.50,
      "availability": "medium"
    }
  ]
}
